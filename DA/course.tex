\documentclass{article}

\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage[french]{babel}

\usepackage{caption}
%\usepackage{pgfplots}
\usepackage{listings}
\usepackage{graphicx}
\usepackage{footnote}
\usepackage{amsmath}
\usepackage{amsthm}
\usepackage{graphicx}
\usepackage{adjustbox}
\usepackage{url}
\usepackage{bbm}
\usepackage{amssymb}
\usepackage{mathrsfs}
\usepackage{multirow}
\usepackage{amsfonts}
\usepackage[boxed,linesnumbered,noend]{algorithm2e}
\usepackage{qcircuit}
\usepackage{enumitem}
\usepackage{eurosym}

\newtheorem{thm}{Theorem}
\newtheorem{prop}{Propriety}
\newtheorem{lemma}{Lemma}
\newtheorem{defi}{Definition}
\newtheorem{coro}{Corollary}



\setlength{\oddsidemargin}{0pt}
% Marge gauche sur pages impaires
\setlength{\evensidemargin}{0pt}
% Marge gauche sur pages paires
\setlength{\textwidth}{470pt}
% Largeur de la zone de texte 
\setlength{\topmargin}{0pt}
% Pas de marge en haut
\setlength{\headheight}{13pt}
% Haut de page
\setlength{\headsep}{10pt}
% Entre le haut de page et le texte
\setlength{\footskip}{40pt}
% Bas de page + séparation
\setlength{\textheight}{630pt}
% Hauteur de la zone de texte

\title{Donnée et Apprentissage}
\author{Nicolas Vayatis\\
ENS Cachan}
\date{}

\newcommand{\note}{\medskip\noindent\underline}
\newcommand{\transpose}{\hspace{.1em}{}^t\hspace{-.1em}}


\begin{document}
\maketitle
\tableofcontents
\newpage


Notre professeur fait partie du labo CMLA (\emph{Centre de Mathématiques et de Leurs Applications}) faisant parti du MLMDA (\emph{Machine Learning and Massive Data Analysis}) étudiant principalement :
\begin{itemize}
\item Optimisation séquentielle et apprentissage actif
\item Machine Learning sur des signaux temporels
\item Processus de diffusion dans les réseaux avec des applications dans la santé publique (virus) et propagation d'information (virus informatique et réseaux sociaux)
\end{itemize}

Le laboratoire effectue principalement de la recherche (publications) et de la vulgarisation (pour les industries, les politiques, etc) et également des outils numérique (codes, portails, logiciel).
\bigskip

\section{Introduction}
Il existe trois grands problèmes avec les données :
\begin{itemize}
\item Classification (Apprentissage supervisé) : labels discret ($\to$ catégories)
\item Régression (Apprentissage supervisé) : labels continus ($\to$ prédire un prix)
\item Clustering ou segmentation (Apprentissage non supervisé $\to$ pas de labels)
\end{itemize}

Il existe également deux approches :
\begin{itemize}
\item L'approche statistique classique \emph{paramétrique}
\item L'approche par apprentissage \emph{non paramétrique}
\end{itemize}

\paragraph{Principe :}
De par des données historiques $Z_i = (\underbrace{X_i}_{\text{mesures}},\underbrace{Y_i}_{\substack{\text{label si}\\\text{cadre supervisé}}})$, après un apprentissage $A$ fournit une transformée $\hat{f}$ permettant une \emph{règle de décision}, qui est le résultat de $\hat{f}(X_{n+1})$. La fonction $\hat{f}$ est testée, ce qui permet de juger ses performances avant son utilisation.
\bigskip

En statistique classique :
\begin{itemize}
\item On fixe la famille de lois qui génère les $Z_i$
\item On en estime les paramètre de la loi, par exemple avec des méthodes de maximum de vraisemblance
\item On fait du plug-in pour construire la règle de décision
\end{itemize}
\bigskip

En apprentissage :
\begin{itemize}
\item On fixe une structure de fonctions pour les règles de décision
Par exemple
\[f_{\omega, \omega_0} (x) = 
\begin{cases}
\text{"chat"} & \text{si} \quad \omega^T x + \omega_0 > 0\\
\text{"chien} & \text{sinon}\\
\end{cases}\]
\item On fixe un critère de performance, par exemple :
\[\hat{L}_n (f)= \dfrac{1}{n}\sum_{i=1}^{n} \mathbbm{1} \{ (f(X_i) = \text{"chien"} \land Y_i=\text{"chat"}) \lor (f(X_i)=\text{"chat"} \land Y_i=\text{"chien"} \} \]
\item L'algorithme d'apprentissage doit minimiser $\hat{L}_n (f_{\omega,\omega_0})$ sur $\mathcal{F}$
\end{itemize}

\paragraph{Loi du mélange}
Soit $X$ un vecteur aléatoire sur $\mathbb{R}^d$ suivant une loi de mélange. On considère $K$ composantes de loi de densité $f_k$ pour $1\leq k \leq K$.

Un paramètre du mélange est $p=(p_1, ... p_K) \in \Delta_K \subset \mathbb{R}^K$ ou $\Delta_K$ est un simplexe de $\mathbb{R}^K$ :
\[\Delta_K = \big\{ p = (p_1,...,p_K)^T \in \mathbb{R}^K_+ : \sum_{k=1}^K p_k = 1 \big\}\]

La densité du mélange est la loi de $X$ :
\[ f_X(x) = \sum_{k=1}^K p_kf_k(x) \qquad \forall x\in \mathbb{R}^d\]


\paragraph{Variables latentes (labels)}
%Cf slides
On note $Y = (Y_1, ..., Y_k)^T$ avec $Y_K \in \{0,1\}$, $\sum_{k=1}^K Y_k = 1$.
Les $Y_k$ sont des drapeaux exclusifs.
%TODO


\paragraph{Quels Problème décisionnels ?}

\begin{enumerate}
\item Clustering ou classification non supervisée : 
\end{enumerate}

%TODO

\subsection{Expectation Maximisation}

\begin{defi}[Maximum de vraisemblance]
Soit $Z_1,...,Z_n$ des variables aléatoires indépendantes et de même loi $z \mapsto f(z,\theta*)$,  $\theta*$ paramètre inconnu. On appelle maximum de vraisemblance l'estimateur de $\theta*$ défini par 
\[\hat{\theta} \in \arg \max_{\theta\in\Theta} \prod_{i=1}^n f(Z_i, \theta)\]

On utilise souvent la log-vraisemblance du modèle du mélange gaussien pour l'observation $X$ :
%TODO

\end{defi}



\section{Apprentissage Statistique}
Soit $X$ le vecteur des caractéristiques et $Y$ la classification en sortie du modèle. On modélise
\[Y = f(X) + \epsilon\]
Avec $\epsilon$ une variation aléatoire.
\bigskip

Avec un $f$ bien choisi on peut faire des prédictions sur de nouveaux points $X=(x_1,...,x_p)$. On peut également comprendre quels composants $X=(X_1,X_2,...,X_p)$ sont important pour expliquer $Y$, et lesquels sont hors de propos. Selon la complexité de $f$, il peut même être possible de comprendre dans quelle mesure chaque composant $X_j$ de $X$ affecte $Y$.

\paragraph{Existe-t-il une meilleure $f(X)$ ?}
Oui, l'espérance conditionnelle de $Y$ sachant $X$ soit $\mathbb{E}(Y|X=x)$. Cette fonction $f(x) \mapsto \mathbb{E}(Y|X=x)$ est appelé \emph{fonction de régression}. C'est elle qui vérifie le minimum du critère \emph{des moindres carrés :}
\[R_{(X,Y)}(f) = \mathbb{E}[\big(Y-f(X)\big)^2]\]


\begin{thm}
$f(x) \mapsto \mathbb{E}(Y|X=x)$ réalise le minimum de $R_{(X,Y)}(f) = \mathbb{E}[\big(Y-f(X)\big)^2]$.
\end{thm}

$\epsilon = Y - f(x)$ est \emph{l'erreur irréductible} : même lorsque l'on connait $f(x)$, on fera toujours des erreurs de prédiction !

\paragraph{Soucis :} on ne connait pas la loi des données : il faut \emph{l'estimer}. Pour ce faire, on prend une fenêtre et $\hat{f}(x) = \text{Ave}(Y|X \in \mathcal{N}(x))$ où $\mathcal{N}(x)$ est un voisinage de $x$.

\paragraph{La malédiction de la dimension}
En prenant des intervalles fixes, en grande dimension il se passe "des choses bizarres" $\to$ les points deviennent très loin les uns des autres. Autrement dit, le volume nécessaire pour garder la même quantité de points à l'intérieur augmente fortement.

\section{Régression Linéaire}
\begin{defi}
Un modèle linéaire de dimension $p$ est un $p+1$-uplet de paramètres notés $\beta_k$. La fonction linéaire modélisée est alors :
\[f_L(X) = \beta_0 + \beta_1X_1 + ... + \beta_p X_p\]

On peut également poser $\beta = \begin{pmatrix}
\beta_1\\
\vdots\\
\beta_p\\
\end{pmatrix}$
et ainsi
\[f_{\beta,\beta_0} = \transpose \beta . x + \beta_0\]
\end{defi}

Le critère empirique est alors 
\[\hat{R}_n(f_{\beta,\beta_0}) = \dfrac{1}{n}\sum_{i=1}^n \big( Y_i - (\beta_0 + \transpose\beta X_i)^2\big)\]

\paragraph{Remarque :} On peut également estimer de cette manière  n'importe quelle fonction polynomiale :
\begin{align*}
f(X) & = \beta_0 + \transpose \beta.X\\
& = \transpose\tilde{\beta}\cdot \begin{pmatrix}
1 \\ X\\
\end{pmatrix}
\end{align*}
Que l'on peut généraliser en 
\[f(X) = \transpose \tilde{\beta} . g(X)\]
Avec par exemple $g(X) = \begin{pmatrix}
1\\X\\X^2\\X^3\\
\end{pmatrix}$ pour un polynôme de degrés 3.

\paragraph{Problèmes possibles :}
\begin{itemize}
\item Sur-apprentissage : apprendre des spécificités liées aux données et non à la structure implicite sous-jacente que l'on cherche à estimer
\item Sous-apprentissage :  ne pas apprendre suffisamment de caractéristique de la part des données
\end{itemize}
\bigskip


Il faut souvent faire des choix :
\begin{itemize}
\item Prédiction vs interprétabilité
\item Sur vs sous apprentissage 
\item Parcimonie vs boite noire
\item Monitorage de la règle de décision le dans temps (Réutilisabilité ?)
\end{itemize}


\paragraph{Comment estimer l'efficacité d'un modèle ?} On peut découper en deux les données d'apprentissage, une partie pour l'apprentissage et l'autre pour le test.

\paragraph{Choix variance-bias} Supposons que l'on veut adapter un modèle $\hat{f}(x)$ à des données d'apprentissages $\mathtt{Tr}$, et soit $(x_0, y_0)$ une observation tirée depuis la population. Si le vrai modèle est $Y= f(X) + \epsilon$ avec $f(x)=\mathbb{E}(Y|X=x)$ et $\epsilon$ un bruit indépendant de $X$, alors
\[\mathbb{E}\Big(Y - \hat{f}(X)\Big)^2 = \mathbb{V}\big(\hat{f}(X)\big) + [\text{Bias}(\hat{f}(X))]^2 + \mathbb{V}(\epsilon)\]

Avec $\text{Bias}(\hat{f}(x_0))=\mathbb{E}(\hat{f}(X))-f(X)$

\paragraph{Estimation des paramètres par les moindres carrés}
L'objectif est de minimiser $(y_i - \beta_0 \beta_i x_i)^2$

\begin{defi}[RSS]
\[\text{RSS} = e_1^2 + e_2^2 + ... + e_n^2 = (y_1 - \hat{\beta}_0 - \hat{\beta}_1.x_1)^2 + ... + (y_n - \hat{\beta}_0 - \hat{\beta}_1 x_n)^2\]
\end{defi}

\begin{defi}[$t$-statistique et $p$-value]
\[t=\dfrac{\hat{\beta}_1 - 0}{SE(\hat{\beta}_1)}\]

$\mathbb{P}(|X|>|t|)$ est une $p$-value.
\end{defi}

%TODO


\begin{adjustbox}{max width=\textwidth}
\begin{tabular}{c|c|c|c|c}
Problème & Supervisé & Non Supervisé & Objectif & Critère\\
\hline
Régression & $Y\in \mathbb{R}$ & & $Y$ & Erreur de prédiction/Moindre carrées\\
Classification & $Y\in \{0,1\}$ & & $Y$ & Erreur de prédiction / Taux d'erreur\\
Clustering & & $X$, $Y$ non observé & $Y$ & pas de critère clair\\
Scoring & $Y\in\{ 0, 1\}$ & & $Y$ & AUC, courbe Roc, courbes ROC, courbe Précision/Rappel\\
\hline
\end{tabular}
\end{adjustbox}





\end{document}